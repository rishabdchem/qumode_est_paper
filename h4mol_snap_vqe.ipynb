{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTuUo9-GBwrx"
      },
      "source": [
        "# Qumode VQE for an eight-qubit Hamiltonian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNVAX1o1wTXo"
      },
      "source": [
        "Explore `TensorFlow` optimizers for VQE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0tBc-IKGzVS"
      },
      "source": [
        "## Prerequisite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6PZ-ceICzov"
      },
      "source": [
        "Installation cells for Google Colab users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkHT4A_rYRr8",
        "outputId": "3298f4bf-38f9-441c-b523-8a5649f51ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qutip\n",
            "  Downloading qutip-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from qutip) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from qutip) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from qutip) (24.2)\n",
            "Downloading qutip-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qutip\n",
            "Successfully installed qutip-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install qutip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wthDw26AyZ-9",
        "outputId": "ae87aab6-b1b9-400b-d296-d713b2db57d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_probability==0.23.0\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (1.26.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (5.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.23.0) (0.1.8)\n",
            "Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_probability\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.24.0\n",
            "    Uninstalling tensorflow-probability-0.24.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.24.0\n",
            "Successfully installed tensorflow_probability-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_probability==0.23.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1qVw4ZiCgl7",
        "outputId": "d68ec3b2-cbd5-405e-cbc0-61f4742789fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting silence-tensorflow\n",
            "  Downloading silence_tensorflow-1.2.3.tar.gz (7.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: silence-tensorflow\n",
            "  Building wheel for silence-tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silence-tensorflow: filename=silence_tensorflow-1.2.3-py3-none-any.whl size=6749 sha256=c2c54c7027c85954e2c8f7ad74995f6852ed3f273130a00071f6c41127809250\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/91/a1/2d32c0ea21439c6367fe1acaa2d3a0377a95ae51cf47c13521\n",
            "Successfully built silence-tensorflow\n",
            "Installing collected packages: silence-tensorflow\n",
            "Successfully installed silence-tensorflow-1.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install silence-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09HjHbCCfWnI",
        "outputId": "77eb9ca3-6a3c-45f5-80cf-3bacca7038a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openfermion\n",
            "  Downloading openfermion-1.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting cirq-core~=1.0 (from openfermion)\n",
            "  Downloading cirq_core-1.4.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting deprecation (from openfermion)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: h5py>=2.8 in /usr/local/lib/python3.10/dist-packages (from openfermion) (3.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from openfermion) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from openfermion) (1.26.4)\n",
            "Collecting pubchempy (from openfermion)\n",
            "  Downloading PubChemPy-1.0.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.10/dist-packages (from openfermion) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from openfermion) (1.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from openfermion) (1.13.1)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion) (24.3.0)\n",
            "Collecting duet>=0.2.8 (from cirq-core~=1.0->openfermion)\n",
            "  Downloading duet-0.2.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion) (2.2.2)\n",
            "Collecting sortedcontainers~=2.0 (from cirq-core~=1.0->openfermion)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion) (4.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion) (2024.12.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation->openfermion) (24.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->openfermion) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cirq-core~=1.0->openfermion) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->cirq-core~=1.0->openfermion) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->cirq-core~=1.0->openfermion) (1.17.0)\n",
            "Downloading openfermion-1.6.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_core-1.4.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading duet-0.2.9-py3-none-any.whl (29 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: pubchempy\n",
            "  Building wheel for pubchempy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pubchempy: filename=PubChemPy-1.0.4-py3-none-any.whl size=13819 sha256=b45be329d923e03d7e7ba75218a0ac2ff284f05d0098bc1fbea2d16254e28406\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/7c/45/18a0671e3c3316966ef7ed9ad2b3f3300a7e41d3421a44e799\n",
            "Successfully built pubchempy\n",
            "Installing collected packages: sortedcontainers, pubchempy, duet, deprecation, cirq-core, openfermion\n",
            "Successfully installed cirq-core-1.4.1 deprecation-2.1.0 duet-0.2.9 openfermion-1.6.1 pubchempy-1.0.4 sortedcontainers-2.4.0\n",
            "Collecting openfermionpyscf\n",
            "  Downloading openfermionpyscf-0.5-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: openfermion>=0.5 in /usr/local/lib/python3.10/dist-packages (from openfermionpyscf) (1.6.1)\n",
            "Collecting pyscf (from openfermionpyscf)\n",
            "  Downloading pyscf-2.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from openfermionpyscf) (8.3.4)\n",
            "Requirement already satisfied: cirq-core~=1.0 in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (1.4.1)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (2.1.0)\n",
            "Requirement already satisfied: h5py>=2.8 in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (3.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (1.26.4)\n",
            "Requirement already satisfied: pubchempy in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (1.0.4)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (1.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from openfermion>=0.5->openfermionpyscf) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyscf->openfermionpyscf) (75.1.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->openfermionpyscf) (1.2.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->openfermionpyscf) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->openfermionpyscf) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->openfermionpyscf) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->openfermionpyscf) (2.2.1)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (24.3.0)\n",
            "Requirement already satisfied: duet>=0.2.8 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (0.2.9)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (2.2.2)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (4.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion>=0.5->openfermionpyscf) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion>=0.5->openfermionpyscf) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion>=0.5->openfermionpyscf) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18->openfermion>=0.5->openfermionpyscf) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->openfermion>=0.5->openfermionpyscf) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->cirq-core~=1.0->openfermion>=0.5->openfermionpyscf) (1.17.0)\n",
            "Downloading openfermionpyscf-0.5-py3-none-any.whl (16 kB)\n",
            "Downloading pyscf-2.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyscf, openfermionpyscf\n",
            "Successfully installed openfermionpyscf-0.5 pyscf-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openfermion\n",
        "!pip install openfermionpyscf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW9_kkM5C6Ep"
      },
      "source": [
        "Import libaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCouQA6tC-gk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import qutip as qt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "wV8jfE0osifS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5iGTNuwfOLg"
      },
      "outputs": [],
      "source": [
        "from openfermion.chem import MolecularData\n",
        "from openfermion.transforms import get_fermion_operator, jordan_wigner, bravyi_kitaev\n",
        "from openfermion.ops import FermionOperator, QubitOperator\n",
        "from openfermion.ops.representations import get_tensors_from_integrals\n",
        "from openfermionpyscf import run_pyscf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FapDoKpBCkzK"
      },
      "outputs": [],
      "source": [
        "from silence_tensorflow import silence_tensorflow\n",
        "silence_tensorflow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxiHaz2DcgFG",
        "outputId": "c9430f49-d999-48ad-df4b-b4cfe5dbebff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rishabdchem/qumode_est_paper/\n",
        "\n",
        "import sys\n",
        "sys.path.append('./qumode_est_paper/')\n",
        "%cd qumode_est_paper/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemSMnUZTp5M"
      },
      "source": [
        "## Circuits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2sG93TuTrQS"
      },
      "source": [
        "### Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44qHE7IcTtSQ"
      },
      "outputs": [],
      "source": [
        "def qt2tf(qt_object, dtype=tf.complex128):\n",
        "    if tf.is_tensor(qt_object) or qt_object is None:\n",
        "        return qt_object\n",
        "    return tf.constant(qt_object.full(), dtype=dtype)\n",
        "\n",
        "\n",
        "def get_cvec_tf(r, theta, dtype=tf.complex128):\n",
        "    real_part = r * tf.cos(theta)\n",
        "    imag_part = r * tf.sin(theta)\n",
        "    return tf.complex(real_part, imag_part)\n",
        "\n",
        "\n",
        "def get_cvec_np(r, theta):\n",
        "    r = np.array(r)\n",
        "    theta = np.array(theta)\n",
        "    return r * np.exp(1j * theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTnBXlR6TyRY"
      },
      "outputs": [],
      "source": [
        "def qproj00_qt():\n",
        "    return qt.basis(2, 0).proj()\n",
        "\n",
        "\n",
        "def qproj11_qt():\n",
        "    return qt.basis(2, 1).proj()\n",
        "\n",
        "\n",
        "def qproj01_qt():\n",
        "    op = np.array([[0, 1], [0, 0]])\n",
        "    return qt.Qobj(op)\n",
        "\n",
        "\n",
        "def qproj10_qt():\n",
        "    op = np.array([[0, 0], [1, 0]])\n",
        "    return qt.Qobj(op)\n",
        "\n",
        "\n",
        "def hadamard_qt():\n",
        "    op = (1/np.sqrt(2)) * np.array([[1, 1], [1, -1]])\n",
        "    return qt.Qobj(op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXnJW1SDTy9c"
      },
      "source": [
        "### SNAP-displacement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cVRI9RbT2Ua"
      },
      "source": [
        "We will use `QuTip` to generate SNAP-displacement ansatz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfSqfjZlT4S9"
      },
      "outputs": [],
      "source": [
        "def unpack_params_snap_disp(X, nfock):\n",
        "    # Initialize\n",
        "    ndepth = X.shape[0] // (nfock + 1)\n",
        "\n",
        "    # Unpack\n",
        "    alpha = X[:ndepth].copy()\n",
        "    d1 = ndepth * nfock\n",
        "    theta = X[ndepth:ndepth+d1].reshape((ndepth, nfock))\n",
        "\n",
        "    return alpha, theta\n",
        "\n",
        "\n",
        "def pack_params_snap_disp(alpha, theta):\n",
        "    # Initialize\n",
        "    ndepth = alpha.shape[0]\n",
        "    nfock = theta.shape[1]\n",
        "    dim = (nfock + 1) * ndepth\n",
        "    X = np.zeros((dim,))\n",
        "\n",
        "    # Pack\n",
        "    X[:ndepth] = alpha.copy()\n",
        "    d1 = ndepth * nfock\n",
        "    X[ndepth:ndepth+d1] = theta.reshape(-1)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOzngioNT7px"
      },
      "source": [
        "Selective number-dependent arbitray phase (SNAP) and displacement operator ([reference](https://doi.org/10.1103/PhysRevA.92.040303))\n",
        "\n",
        "\\begin{align*}\n",
        "U (\\alpha, \\vec{\\theta})\n",
        "&= S (\\vec{\\theta}) \\: D (\\alpha),\n",
        "\\\\\n",
        "S (\\vec{\\theta})\n",
        "&= \\sum_{n = 0}^{L - 1} \\: \\exp ( i \\: \\theta_n ) \\: |n \\rangle \\langle n|,\n",
        "\\\\\n",
        "D (\\alpha)\n",
        "&= e^{ \\alpha \\: ( a^\\dagger - a ) }.\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muSLrj7ST53z"
      },
      "outputs": [],
      "source": [
        "def snap_disp_op_qt(alpha, thetavec):\n",
        "    \"\"\"\n",
        "    SNAP-displacement operator.\n",
        "\n",
        "    Arguments:\n",
        "    alpha -- displacement coefficient\n",
        "    thetavec -- SNAP parameters\n",
        "    \"\"\"\n",
        "    # Initialize\n",
        "    nfock = thetavec.shape[0]\n",
        "\n",
        "    # SNAP\n",
        "    S2 = np.exp(1j * thetavec[0]) * qt.basis(nfock, 0).proj()\n",
        "    for i in range(1, nfock):\n",
        "        S2 += np.exp(1j * thetavec[i]) * qt.basis(nfock, i).proj()\n",
        "\n",
        "    # Displacement\n",
        "    D2 = qt.displace(nfock, alpha)\n",
        "\n",
        "    return S2 * D2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmYvpDsrT-dG"
      },
      "source": [
        "Build the ansatz matrix of depth $N_d$\n",
        "\n",
        "$$ \\mathcal{U} (\\vec{\\alpha}, \\bar{\\theta})\n",
        "= U (\\alpha_{N_d}, \\vec{\\theta}_{N_d}) \\cdots\n",
        "U (\\alpha_1, \\vec{\\theta}_1),\n",
        "$$\n",
        "\n",
        "where $\\vec{\\alpha}$ is an $N_d$-dimensional vector and\n",
        "$ \\bar{\\theta}_{N_d \\times L} $ is a matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dEZI_MsUAWs"
      },
      "outputs": [],
      "source": [
        "def snap_disp_ansatz_qt(Xvec, nfock):\n",
        "    \"\"\"\n",
        "    SNAP-displacement ansatz.\n",
        "\n",
        "    Arguments:\n",
        "    Xvec -- ansatz parameters\n",
        "    nfock -- Fock cutoff\n",
        "    \"\"\"\n",
        "    # Initialize\n",
        "    alphavec, thetamat = unpack_params_snap_disp(Xvec, nfock)\n",
        "    ndepth = thetamat.shape[0]\n",
        "    uni = snap_disp_op_qt(alphavec[0], thetamat[0, :])\n",
        "\n",
        "    # Check\n",
        "    if ndepth == 1:\n",
        "        return uni.full()\n",
        "\n",
        "    # Loop through blocks\n",
        "    for i in range(1, ndepth):\n",
        "        new_uni = snap_disp_op_qt(alphavec[i], thetamat[i, :])\n",
        "        uni = ( new_uni * uni )\n",
        "\n",
        "    return uni.full()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8IL0xpYUVft"
      },
      "source": [
        "### TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB3uOxK9UV0X"
      },
      "outputs": [],
      "source": [
        "def identity_tf(N, dtype=tf.complex128):\n",
        "    return tf.eye(N, dtype=dtype)\n",
        "\n",
        "\n",
        "def destroy_tf(N, dtype=tf.complex128):\n",
        "    a = tf.linalg.diag(tf.sqrt(tf.range(1, N, dtype=tf.float64)), k=1)\n",
        "    return tf.cast(a, dtype=dtype)\n",
        "\n",
        "\n",
        "def create_tf(N, dtype=tf.complex128):\n",
        "    return tf.cast(tf.linalg.adjoint(destroy_tf(N, dtype)), dtype=dtype)\n",
        "\n",
        "\n",
        "def num_proj_tf(N, j, dtype=tf.complex128):\n",
        "    op = qt.basis(N, j).proj()\n",
        "    return qt2tf(op, dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmUC_MytUXg3"
      },
      "outputs": [],
      "source": [
        "def displace_tf(N, alpha, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    Complex-valued matrix representation of\n",
        "\n",
        "    D (alpha) = exp( alpha b! - alpha* b ).\n",
        "\n",
        "    Arguments:\n",
        "    alpha -- displacement parameter\n",
        "    N -- qumode dimension\n",
        "    dtype -- data type\n",
        "    \"\"\"\n",
        "    gen = ( tf.cast(alpha, dtype=dtype) * create_tf(N, dtype) )\n",
        "    gen -= ( tf.cast(tf.math.conj(alpha), dtype=dtype) * destroy_tf(N, dtype) )\n",
        "\n",
        "    return tf.cast(tf.linalg.expm(gen), dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Cyk6KNeUZH1"
      },
      "outputs": [],
      "source": [
        "def snap_disp_op_tf(alpha, thetavec, nfock, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    SNAP-displacement operator.\n",
        "\n",
        "    Arguments:\n",
        "    alpha -- displacement coefficient\n",
        "    thetavec -- SNAP parameters\n",
        "    \"\"\"\n",
        "    # SNAP term\n",
        "    S2 = tf.exp( 1j * tf.cast( thetavec[0], dtype=dtype) ) * num_proj_tf(nfock, 0, dtype=dtype)\n",
        "    for i in range(1, nfock):\n",
        "        S2 += tf.exp( 1j * tf.cast( thetavec[i], dtype=dtype) ) * num_proj_tf(nfock, i, dtype=dtype)\n",
        "\n",
        "    # Displacement term\n",
        "    D2 = displace_tf(nfock, alpha, dtype=dtype)\n",
        "\n",
        "    # Return the combined operator\n",
        "    return tf.cast(tf.linalg.matmul(S2, D2), dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43us0SD7UccC"
      },
      "outputs": [],
      "source": [
        "def beam_splitter_tf(theta, phi, nfocks, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    BS (theta, phi) = exp[ i (theta/2) ( exp(i phi) b1! b2 + h.c. ) ].\n",
        "\n",
        "    Arguments:\n",
        "    theta, phi -- rotation parameters\n",
        "    nfocks -- Fock cutoffs\n",
        "    \"\"\"\n",
        "    # Operators\n",
        "    b1 = tf.linalg.LinearOperatorFullMatrix(destroy_tf(nfocks[0], dtype=dtype), dtype)\n",
        "    b2 = tf.linalg.LinearOperatorFullMatrix(destroy_tf(nfocks[1], dtype=dtype), dtype)\n",
        "    b1dag = tf.linalg.LinearOperatorFullMatrix(create_tf(nfocks[0], dtype=dtype), dtype)\n",
        "    b2dag = tf.linalg.LinearOperatorFullMatrix(create_tf(nfocks[1], dtype=dtype), dtype)\n",
        "\n",
        "    # Tensor products\n",
        "    op1 = tf.linalg.LinearOperatorKronecker([b1dag, b2]).to_dense()\n",
        "    op2 = tf.linalg.LinearOperatorKronecker([b1, b2dag]).to_dense()\n",
        "\n",
        "    # Generator of the beam splitter operator\n",
        "    gen = tf.exp(1j * tf.cast(phi, dtype=dtype)) * op1\n",
        "    gen += tf.exp(-1j * tf.cast(phi, dtype=dtype)) * op2\n",
        "\n",
        "    # Hamiltonian\n",
        "    H = 1j * (tf.cast(theta, dtype=dtype) / 2) * gen\n",
        "\n",
        "    # Unitary\n",
        "    return tf.cast(tf.linalg.expm(H), dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3d-manVUeaB"
      },
      "source": [
        "### Multimode SNAP-displacement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fof1MQoKUg0f"
      },
      "source": [
        "SNAP-displacement gates with beamsplitter for two qumodes\n",
        "\n",
        "\\begin{align*}\n",
        "U (\\beta, \\phi, \\vec{\\alpha}, \\vec{\\theta}_1, \\vec{\\theta}_2)\n",
        "&= \\big[ S (\\vec{\\theta}_1) \\: D (\\alpha_1) \\otimes I \\big] \\:\n",
        "\\big[ I \\otimes S (\\vec{\\theta}_2) \\: D (\\alpha_2) \\big] \\:\n",
        "BS_{1, 2} (\\beta, \\phi),\n",
        "\\\\\n",
        "BS_{1, 2} (\\beta, \\phi)\n",
        "&= e^{ i \\frac{\\beta}{2} \\big(\n",
        "e^{i \\phi} a_1^\\dagger a_2 + \\text{h.c.} \\big)},\n",
        "\\end{align*}\n",
        "where $\\vec{\\alpha}$ is a two-dimensional vector,\n",
        "$\\vec{\\theta}_1$ is an $L_1$-dimensional vector, $\\vec{\\theta}_2$ is an $L_2$-dimensional vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4YxEFlkUi1P"
      },
      "outputs": [],
      "source": [
        "def multimode_snap_disp_op_tf(beta, phi, alpha_vec, theta_vec1, theta_vec2, nfocks, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    Qumode-qumode SNAP-displacement.\n",
        "\n",
        "    Arguments:\n",
        "    beta, phi -- beamsplitter parameters\n",
        "    alpha_vec -- displacement parameters\n",
        "    theta_vec1, theta_vec2 -- SNAP parameters\n",
        "    \"\"\"\n",
        "    # SNAP-displacement operators\n",
        "    op1 = snap_disp_op_tf(alpha_vec[0], theta_vec1, nfocks[0], dtype=dtype)\n",
        "    op2 = snap_disp_op_tf(alpha_vec[1], theta_vec2, nfocks[1], dtype=dtype)\n",
        "\n",
        "    # Matrices\n",
        "    op1_mat = tf.linalg.LinearOperatorFullMatrix(op1, dtype)\n",
        "    op2_mat = tf.linalg.LinearOperatorFullMatrix(op2, dtype)\n",
        "\n",
        "    # Identity operators\n",
        "    identity1 = tf.linalg.LinearOperatorIdentity(nfocks[0], dtype=dtype)\n",
        "    identity2 = tf.linalg.LinearOperatorIdentity(nfocks[1], dtype=dtype)\n",
        "\n",
        "    # Kronecker products\n",
        "    SD1 = tf.linalg.LinearOperatorKronecker([op1_mat, identity2]).to_dense()\n",
        "    SD2 = tf.linalg.LinearOperatorKronecker([identity1, op2_mat]).to_dense()\n",
        "\n",
        "    # Kronecker product result\n",
        "    SDtwo = tf.linalg.matmul(SD2, SD1)\n",
        "\n",
        "    # Beamsplitter\n",
        "    BS = beam_splitter_tf(beta, phi, nfocks, dtype=dtype)\n",
        "\n",
        "    return tf.cast(tf.linalg.matmul(BS, SDtwo), dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6yloMM-UlHC"
      },
      "source": [
        "Build the ansatz matrix of depth $N_d$\n",
        "\n",
        "$$ \\mathcal{U} (\\vec{\\beta}, \\vec{\\phi}, \\bar{\\alpha},\n",
        "\\bar{\\theta}^{(1)}, \\bar{\\theta}^{(2)})\n",
        "= U (\\beta_{N_d}, \\phi_{N_d}, \\vec{\\alpha}_{N_d}, \\vec{\\theta}_{N_d}^{(1)}, \\vec{\\theta}_{N_d}^{(2)})\n",
        "\\: \\cdots \\:\n",
        "U (\\beta_1, \\phi_1, \\vec{\\alpha}_1, \\vec{\\theta}_1^{(1)}, \\vec{\\theta}_1^{(2)}),\n",
        "$$\n",
        "where $\\vec{\\beta}, \\vec{\\phi}$ are $N_d$-dimensional vectors, $\\bar{\\alpha}$ is a matrix of dimensions $N_d \\times 2$,\n",
        "$\\bar{\\theta}^{(1)}$ is a matrix of dimensions $N_d \\times L_1$, and\n",
        "$\\bar{\\theta}^{(2)}$ is a matrix of dimensions $N_d \\times L_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvI3cSnvUe3_"
      },
      "outputs": [],
      "source": [
        "def pack_params_ansatz(beta, phi, alpha_vec, theta_vec1, theta_vec2):\n",
        "    # Flatten each parameter tensor into a 1D tensor (vector)\n",
        "    beta_flat = tf.reshape(beta, [-1])\n",
        "    phi_flat = tf.reshape(phi, [-1])\n",
        "    alpha_flat = tf.reshape(alpha_vec, [-1])  # Flatten the alpha matrix\n",
        "    theta1_flat = tf.reshape(theta_vec1, [-1])  # Flatten the theta1 matrix\n",
        "    theta2_flat = tf.reshape(theta_vec2, [-1])  # Flatten the theta2 matrix\n",
        "\n",
        "    # Concatenate all flattened tensors into a single vector\n",
        "    packed_vec = tf.concat([beta_flat, phi_flat, alpha_flat, theta1_flat, theta2_flat], axis=0)\n",
        "\n",
        "    return tf.Variable(packed_vec)\n",
        "\n",
        "\n",
        "def unpack_params_ansatz(packed_vec, ndepth, L1, L2):\n",
        "    # Extract the lengths of each individual parameter\n",
        "    beta_size = ndepth\n",
        "    phi_size = ndepth\n",
        "    alpha_size = ndepth * 2\n",
        "    theta1_size = ndepth * L1\n",
        "    theta2_size = ndepth * L2\n",
        "\n",
        "    # Unpack the vector into its original components\n",
        "    beta = tf.reshape(packed_vec[:beta_size], [beta_size])\n",
        "    phi = tf.reshape(packed_vec[beta_size:beta_size + phi_size], [phi_size])\n",
        "    alpha_vec = tf.reshape(packed_vec[beta_size + phi_size:beta_size + phi_size + alpha_size], [ndepth, 2])\n",
        "    theta_vec1 = tf.reshape(packed_vec[beta_size + phi_size + alpha_size:beta_size + phi_size + alpha_size + theta1_size], [ndepth, L1])\n",
        "    theta_vec2 = tf.reshape(packed_vec[beta_size + phi_size + alpha_size + theta1_size:], [ndepth, L2])\n",
        "\n",
        "    return beta, phi, alpha_vec, theta_vec1, theta_vec2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBOa20pvUpfT"
      },
      "outputs": [],
      "source": [
        "def multimode_snap_disp_tf(Xvec, ndepth, nfocks, dtype=tf.complex128):\n",
        "    # Initialize\n",
        "    beta, phi, alpha_vec, theta_vec1, theta_vec2 = unpack_params_ansatz(Xvec, ndepth, nfocks[0], nfocks[1])\n",
        "    uni = multimode_snap_disp_op_tf(beta[0], phi[0], alpha_vec[0, :], theta_vec1[0, :],\n",
        "                                    theta_vec2[0, :], nfocks, dtype=dtype)\n",
        "\n",
        "    # Check\n",
        "    if ndepth == 1:\n",
        "        return tf.cast(uni, dtype=dtype)\n",
        "\n",
        "    # Loop through blocks\n",
        "    for i in range(1, ndepth):\n",
        "        new_mat = multimode_snap_disp_op_tf(beta[i], phi[i], alpha_vec[i, :],\n",
        "                                            theta_vec1[i, :], theta_vec2[i, :],\n",
        "                                            nfocks, dtype=dtype)\n",
        "        uni = tf.linalg.matmul(new_mat, uni)\n",
        "\n",
        "    return tf.cast(uni, dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeO4HjsUCo5b"
      },
      "source": [
        "## Qubit operators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_awh0EhJMMwd"
      },
      "source": [
        "### General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZsZRp0lXWVG"
      },
      "source": [
        "`OpenFermion` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkxxTz1LMOY9"
      },
      "outputs": [],
      "source": [
        "def append_ids(qubitstr, nqubits):\n",
        "    \"\"\"\n",
        "    Modify a qubit string so that identities are explicity included.\n",
        "\n",
        "    Arguments:\n",
        "    qubitstr -- Input qubit string as a tuple of tuples\n",
        "    nqubits  -- Number of qubits\n",
        "    \"\"\"\n",
        "    # Initialize a tuple\n",
        "    newstr = [None] * nqubits\n",
        "\n",
        "    # Copy\n",
        "    for p in range(len(qubitstr)):\n",
        "        newstr[qubitstr[p][0]] = qubitstr[p]\n",
        "\n",
        "    # Updates\n",
        "    for p in range(nqubits):\n",
        "        if newstr[p] == None:\n",
        "            newstr[p] = (p, 'I')\n",
        "\n",
        "    return newstr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poLWW0cKMYkE"
      },
      "outputs": [],
      "source": [
        "def qubit_partition(qubitop, nqubit, quditvec):\n",
        "    \"\"\"\n",
        "    Transform one qubit string to a set of a qubit strings based on\n",
        "    the partition chosen.\n",
        "\n",
        "    Arguments:\n",
        "    qubitop  -- A single Pauli operator string as a tuple of tuples\n",
        "    nqubit   -- Number of qubit operators including identity\n",
        "    quditvec -- Qudit vector for reorganizing qubit Hilbert space\n",
        "    \"\"\"\n",
        "    # Check\n",
        "    if sum(quditvec) != nqubit:\n",
        "        raise ValueError(\"Wrong qudit vector elements\")\n",
        "\n",
        "    # A list of tuples\n",
        "    qubitstr = append_ids(qubitop, nqubit)\n",
        "\n",
        "    # New qubit strings\n",
        "    newstrings = []\n",
        "    for j in range(len(quditvec)):\n",
        "        # Initialize\n",
        "        templist = []\n",
        "        # Loop for string as a list\n",
        "        for p in range(quditvec[j]):\n",
        "            # Tuple\n",
        "            temptuple = (p, qubitstr[sum(quditvec[:j]) + p][1])\n",
        "            # Add to list\n",
        "            templist.append(temptuple)\n",
        "        # Update list of strings\n",
        "        newstrings.append(templist)\n",
        "\n",
        "    return newstrings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urejvtizRpOY"
      },
      "outputs": [],
      "source": [
        "def simple_qubit_string(qubitop, nqubit, quditvec):\n",
        "    \"\"\"\n",
        "    Transform one qubit string to a set of a qubit strings based on\n",
        "    the partition chosen.\n",
        "\n",
        "    Arguments:\n",
        "    qubitop  -- A single Pauli operator string as a tuple of tuples\n",
        "    nqubit   -- Number of qubit operators including identity\n",
        "    quditvec -- Qudit vector for reorganizing qubit Hilbert space\n",
        "    \"\"\"\n",
        "    # Check\n",
        "    if sum(quditvec) != nqubit:\n",
        "        raise ValueError(\"Wrong qudit vector elements\")\n",
        "\n",
        "    # A list of tuples\n",
        "    qubitstr = qubit_partition(qubitop, nqubit, quditvec)\n",
        "\n",
        "    # New qubit strings\n",
        "    string_list = []\n",
        "    for j in range(len(quditvec)):\n",
        "        string_list.append(''.join(op for _, op in qubitstr[j]))\n",
        "\n",
        "    return string_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq72joa7UGaP"
      },
      "outputs": [],
      "source": [
        "def qubit_string_from_openfermion(qubitop, nqubit, quditvec):\n",
        "    \"\"\"\n",
        "    Transform a QubitOperator to a set of a qubit strings and coefficients based on\n",
        "    the partition chosen.\n",
        "\n",
        "    Arguments:\n",
        "    qubitop  -- QubitOperator\n",
        "    nqubit   -- Number of qubit operators including identity\n",
        "    quditvec -- Qudit vector for reorganizing qubit Hilbert space\n",
        "    \"\"\"\n",
        "    # Check\n",
        "    if sum(quditvec) != nqubit:\n",
        "        raise ValueError(\"Wrong qudit vector elements\")\n",
        "\n",
        "    # Get data\n",
        "    qubit_strings = list(qubitop.terms.keys())\n",
        "    coeffs = np.array(list( qubitop.terms.values() ))\n",
        "\n",
        "    # New qubit strings\n",
        "    ops_list = []\n",
        "    for qubit_op in qubit_strings:\n",
        "        ops_list.append( simple_qubit_string(qubit_op, nqubit, quditvec) )\n",
        "\n",
        "    return ops_list, coeffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZRP28LaXmbw"
      },
      "source": [
        "`QuTip` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO9HjdoVic-U"
      },
      "outputs": [],
      "source": [
        "def generate_tensor_product(string):\n",
        "    \"\"\"\n",
        "    Generate QuTip object given a string representing a Pauli word.\n",
        "    \"\"\"\n",
        "    # Define a mapping of characters to corresponding QuTiP operators\n",
        "    operator_map = {\n",
        "        'I': qt.qeye(2),  # Identity operator\n",
        "        'X': qt.sigmax(),  # Pauli-X operator\n",
        "        'Y': qt.sigmay(),  # Pauli-Y operator\n",
        "        'Z': qt.sigmaz()   # Pauli-Z operator\n",
        "    }\n",
        "\n",
        "    # Create a list to collect the operators\n",
        "    operators = []\n",
        "\n",
        "    # Append the corresponding operators based on the input string\n",
        "    for char in string:\n",
        "        operators.append(operator_map[char])\n",
        "\n",
        "    # Compute the tensor product of all operators in the list\n",
        "    U = qt.tensor(*operators).full()\n",
        "\n",
        "    return qt.Qobj(U)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "humojANNMHzb"
      },
      "source": [
        "### Specific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GEzWDNGCpow"
      },
      "outputs": [],
      "source": [
        "def snap_uni_four_pauli(pword, data_dict):\n",
        "    \"\"\"\n",
        "    Get SNAP-displacement unitary with Fock cutoff = 16.\n",
        "\n",
        "    Arguments:\n",
        "    pword -- four qubit Pauli word\n",
        "    data_dict -- parameter dictionary\n",
        "    \"\"\"\n",
        "    nfock = 16\n",
        "    Xvec = np.array( data_dict[pword][2] )\n",
        "    U = snap_disp_ansatz_qt(Xvec, nfock)\n",
        "\n",
        "    return U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Z3B-tnb5ZW"
      },
      "outputs": [],
      "source": [
        "def snap_eight_qubit_ham(qubit_op, data_dict):\n",
        "    \"\"\"\n",
        "    Get a list of SNAP-displacement unitary pairs (U1, U2),\n",
        "    each with Fock cutoff = 16.\n",
        "\n",
        "    Arguments:\n",
        "    qubit_op -- eight-qubit openfermion QubitOperator\n",
        "    data_dict -- parameter dictionary\n",
        "    \"\"\"\n",
        "    # Initialize\n",
        "    nqubit = 8\n",
        "    nfock = 16\n",
        "    nqpart = 4\n",
        "    quditvec = [nqpart, nqpart,]\n",
        "\n",
        "    # String and coefficient lists\n",
        "    ops_list, coeffs = qubit_string_from_openfermion(qubit_op, nqubit, quditvec)\n",
        "\n",
        "    # Final\n",
        "    U1_lists = []\n",
        "    U2_lists = []\n",
        "    for i in range(len(coeffs)):\n",
        "        if ops_list[i][0] == 'I' * nqpart:\n",
        "            U1_lists.append( qt.qeye(nfock) )\n",
        "        else:\n",
        "            U1_lists.append( snap_uni_four_pauli(ops_list[i][0], data_dict) )\n",
        "        if ops_list[i][1] == 'I' * nqpart:\n",
        "            U2_lists.append( qt.qeye(nfock) )\n",
        "        else:\n",
        "            U2_lists.append( snap_uni_four_pauli(ops_list[i][1], data_dict) )\n",
        "\n",
        "    return U1_lists, U2_lists, coeffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyGxeMRnXk_G"
      },
      "outputs": [],
      "source": [
        "def pauli_eight_qubit_ham(qubit_op):\n",
        "    \"\"\"\n",
        "    Build the eight-qubit Hamiltonian.\n",
        "\n",
        "    Argument:\n",
        "    qubit_op -- eight-qubit openfermion QubitOperator\n",
        "    \"\"\"\n",
        "    # Initialize\n",
        "    nqubit = 8\n",
        "    nfock = 16\n",
        "    quditvec = [nqubit,]\n",
        "\n",
        "    # String and coefficient lists\n",
        "    ops_list, coeffs = qubit_string_from_openfermion(qubit_op, nqubit, quditvec)\n",
        "\n",
        "    # Final\n",
        "    ham = []\n",
        "    for i in range(len(coeffs)):\n",
        "        term = (coeffs[i] * generate_tensor_product(ops_list[i][0]) )\n",
        "        ham.append(term)\n",
        "\n",
        "    return sum(ham)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyR8EhUzK4gO"
      },
      "source": [
        "### Hamiltonians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Um-wFXZmULA"
      },
      "outputs": [],
      "source": [
        "def ham_linear_sym_h4(R, f2q='JWT'):\n",
        "    \"\"\"\n",
        "    (0) -- (R) -- (2R) -- (3R)\n",
        "\n",
        "    Arguments:\n",
        "    R -- bond distance in Angstrom\n",
        "    f2q -- Fermion to qubit mapping\n",
        "    \"\"\"\n",
        "    # Define parameters\n",
        "    basis = \"sto-3g\"\n",
        "    multiplicity = 1\n",
        "    charge = 0\n",
        "\n",
        "    # XYZ coordinates\n",
        "    geometry = [(\"H\", (0, 0, 0)), \\\n",
        "                (\"H\", (0, 0, R)), \\\n",
        "                (\"H\", (0, 0, 2*R)), \\\n",
        "                (\"H\", (0, 0, 3*R))]\n",
        "\n",
        "    # Define molecule\n",
        "    molecule = MolecularData(geometry, basis, multiplicity, charge)\n",
        "\n",
        "    # Hartree-Fock\n",
        "    hf_molecule = run_pyscf(molecule, run_scf=1)\n",
        "\n",
        "    # Fermionic Hamiltonian\n",
        "    ham_fermi = get_fermion_operator(hf_molecule.get_molecular_hamiltonian())\n",
        "\n",
        "    # Qubit mapping\n",
        "    if f2q == 'JWT':\n",
        "        ham = jordan_wigner(ham_fermi)\n",
        "    elif f2q == 'BKT':\n",
        "        ham = bravyi_kitaev(ham_fermi)\n",
        "\n",
        "    return ham"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H = ham_linear_sym_h4(0.7)"
      ],
      "metadata": {
        "id": "us56kCssSJo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(H.terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3F6152uSQ9r",
        "outputId": "7d563421-af97-4438-ffbc-ec713d0e8905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOMp4RJAmZxd"
      },
      "outputs": [],
      "source": [
        "def fci_linear_sym_h4(R):\n",
        "    \"\"\"\n",
        "    (0) -- (R) -- (2R) -- (3R)\n",
        "\n",
        "    Argument:\n",
        "    R -- bond distance in Angstrom\n",
        "    \"\"\"\n",
        "    # Define parameters\n",
        "    basis = \"sto-3g\"\n",
        "    multiplicity = 1\n",
        "    charge = 0\n",
        "\n",
        "    # XYZ coordinates\n",
        "    geometry = [(\"H\", (0, 0, 0)), \\\n",
        "                (\"H\", (0, 0, R)), \\\n",
        "                (\"H\", (0, 0, 2*R)), \\\n",
        "                (\"H\", (0, 0, 3*R))]\n",
        "\n",
        "    # Define molecule\n",
        "    molecule = MolecularData(geometry, basis, multiplicity, charge)\n",
        "\n",
        "    # Run HF calculation\n",
        "    molecule = run_pyscf(molecule, run_fci=1)\n",
        "\n",
        "    return molecule.hf_energy, molecule.fci_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olo-M0zHmXEE"
      },
      "source": [
        "## Expectation value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljzNkZYacq_A"
      },
      "source": [
        "### Hadamard test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLMYgKFwrVJz"
      },
      "outputs": [],
      "source": [
        "def trace_out_qumodes_tf(state, nfocks):\n",
        "    \"\"\"\n",
        "    Performs a partial trace over the qumodes of a density matrix,\n",
        "    leaving the reduced density matrix for the qubit.\n",
        "\n",
        "    Arguments:\n",
        "    state -- statevector for qubit-qumode-qumode system in TensorFlow\n",
        "    nfock -- Fock cutoffs for two qumodes\n",
        "    \"\"\"\n",
        "    # Initialize\n",
        "    rho = tf.matmul( state, tf.transpose(tf.math.conj(state)) )\n",
        "\n",
        "    # Dimension matching\n",
        "    rho_reshaped = tf.reshape(rho, [2, nfocks[0], nfocks[1], 2, nfocks[0], nfocks[1]])\n",
        "\n",
        "    # Qubit RDM\n",
        "    rho_qubit = tf.einsum('ijkljk->il', rho_reshaped)\n",
        "\n",
        "    return rho_qubit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAEl6OyBo27x"
      },
      "outputs": [],
      "source": [
        "def include_hadamard(U1, U2):\n",
        "    # Fock cutoffs\n",
        "    nfocks = []\n",
        "    nfocks.append(U1.shape[0])\n",
        "    nfocks.append(U2.shape[0])\n",
        "\n",
        "    # U1 part\n",
        "    op1 = qt.tensor(hadamard_qt(), qt.qeye(nfocks[0]), qt.qeye(nfocks[1]))\n",
        "    op2 = qt.tensor(qt.basis(2, 0).proj(), qt.qeye(nfocks[0]), qt.qeye(nfocks[1]))\n",
        "    op2 += qt.tensor(qt.basis(2, 1).proj(), U1, qt.qeye(nfocks[1]))\n",
        "    U1_op = op1 * op2 * op1\n",
        "\n",
        "    # U2 part\n",
        "    op3 = qt.tensor(hadamard_qt(), qt.qeye(nfocks[0]), qt.qeye(nfocks[1]))\n",
        "    op4 = qt.tensor(qt.basis(2, 0).proj(), qt.qeye(nfocks[0]), qt.qeye(nfocks[1]))\n",
        "    op4 += qt.tensor(qt.basis(2, 1).proj(), qt.qeye(nfocks[0]), U2)\n",
        "    U2_op = op3 * op4 * op3\n",
        "\n",
        "    # Final\n",
        "    U = (U1_op * U2_op).full()\n",
        "\n",
        "    return qt.Qobj(U)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaUbRNK_tOif"
      },
      "outputs": [],
      "source": [
        "def hadamard_ops_tf(U1_list, U2_list, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    T(j) = ( U1 (j) x I ) ( I x U2 (j) )\n",
        "\n",
        "    Arguments:\n",
        "    U1_list, U2_list -- list of four-qubit unitaries\n",
        "    \"\"\"\n",
        "    # Initialize\n",
        "    ns = len(U1_list)\n",
        "\n",
        "    # Loop\n",
        "    T_list = []\n",
        "    for i in range(ns):\n",
        "        U1_op = qt.Qobj(U1_list[i])\n",
        "        U2_op = qt.Qobj(U2_list[i])\n",
        "        T_list.append( qt2tf( include_hadamard(U1_op, U2_op), dtype=dtype) )\n",
        "\n",
        "    return T_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk2hz9peQF_4"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def psi_uni_psi_hadamard_tf(state, T2, Zop, nfocks, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    Expectation value Re( <state | ( U1 x I ) ( I x U2 ) | state> ).\n",
        "\n",
        "    Arguments:\n",
        "    state -- qubit-qumode-qumode state in TensorFlow\n",
        "    T2 -- Hadamard-included operator\n",
        "    dtype -- data type\n",
        "    \"\"\"\n",
        "    # T |state>\n",
        "    psi = tf.linalg.matmul(T2, state)\n",
        "\n",
        "    # Extract qubit RDM\n",
        "    rho_qubit = trace_out_qumodes_tf(psi, nfocks)\n",
        "\n",
        "    # <Z>\n",
        "    ov = tf.linalg.trace(tf.matmul(rho_qubit, Zop))\n",
        "\n",
        "    return tf.math.real(ov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTcjFTPzcudx"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qzadjVEsR5y"
      },
      "outputs": [],
      "source": [
        "def state_from_multimode_snap_tf(Xvec, ndepth, nfocks, vac, dtype=tf.complex128):\n",
        "    \"\"\"\n",
        "    Aux-qubit two-qumode state |Psi> = |0> x ( U |0, 0> ).\n",
        "\n",
        "    Arguments:\n",
        "    Xvec -- ansatz parameters\n",
        "    ndepth -- circuit depth\n",
        "    nfocks -- Fock cutoffs for two qumodes\n",
        "    vac -- vacuum state for qubit-qumode-qumode\n",
        "    dtype -- data type\n",
        "    \"\"\"\n",
        "    # Ansatz unitary\n",
        "    U = multimode_snap_disp_tf(Xvec, ndepth, nfocks, dtype=dtype)\n",
        "\n",
        "    # I x U\n",
        "    id_op = tf.linalg.LinearOperatorIdentity(2, dtype=dtype)\n",
        "    U_op = tf.linalg.LinearOperatorFullMatrix(U, dtype)\n",
        "    op = tf.linalg.LinearOperatorKronecker([id_op, U_op]).to_dense()\n",
        "\n",
        "    # ( I x U ) (|0> x |0, 0> )\n",
        "    psi = tf.cast(tf.linalg.matmul(op, vac), dtype=dtype)\n",
        "\n",
        "    return psi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "923vXjwVPTPH"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def energy_val_tf(psi, Zop, nfocks, T_list, coeffs):\n",
        "    \"\"\"\n",
        "    Compute sum(j) C(j) Re( <psi | ( U1 (j) x I ) ( I x U2 (j) ) | psi> ).\n",
        "\n",
        "    Arguments:\n",
        "    psi -- trial state\n",
        "    ndepth -- circuit depth\n",
        "    T_list -- list of four-qubit QuTip unitaries\n",
        "    coeffs - coefficients\n",
        "    nfocks -- Fock cutoffs\n",
        "    \"\"\"\n",
        "    # Convert T_list to a Tensor if it's a list\n",
        "    T_list_tf = tf.convert_to_tensor(T_list, dtype=tf.complex128)\n",
        "\n",
        "    # Assuming `compute_term` is defined properly to use T_list_tf\n",
        "    def compute_term(i):\n",
        "        coeff_tf = tf.cast( tf.gather(coeffs, i), tf.float64 )\n",
        "        term_value = coeff_tf * psi_uni_psi_hadamard_tf(psi, T_list_tf[i], Zop, nfocks)  # Use T_list_tf here\n",
        "        return term_value\n",
        "\n",
        "    # Use tf.map_fn to compute terms in parallel\n",
        "    terms = tf.map_fn(compute_term, tf.range(tf.shape(coeffs)[0]), fn_output_signature=tf.float64)\n",
        "\n",
        "    # Compute the energy as the sum of the terms\n",
        "    en = tf.reduce_sum(terms)\n",
        "\n",
        "    return en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6XBKiSqbvIO"
      },
      "source": [
        "## Optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJip1TwRO4P4"
      },
      "outputs": [],
      "source": [
        "def snap_vqe_tfp(T_list, coeffs, ndepth, niter=100, threshold=1e-08, Xvec=None):\n",
        "    # Initialize\n",
        "    nfocks = [16, 16]\n",
        "    vac_qt = qt.tensor( qt.basis(2, 0), qt.basis(nfocks[0], 0), qt.basis(nfocks[1], 0) )\n",
        "    vac = qt2tf(vac_qt)\n",
        "    P0 = qt2tf( qt.tensor( qt.basis(2, 0).proj(), qt.qeye(nfocks[0]), qt.qeye(nfocks[1]) ) )\n",
        "    Zop = qt2tf(qt.sigmaz())\n",
        "\n",
        "    # Parameter shapes\n",
        "    shape1 = (ndepth,)\n",
        "    shape2 = (ndepth, 2,)\n",
        "    shape3 = (ndepth, nfocks[0],)\n",
        "    shape4 = (ndepth, nfocks[1],)\n",
        "\n",
        "    # Guess\n",
        "    if Xvec is None:\n",
        "        beta = tf.Variable(tf.random.uniform(shape1, minval=0, maxval=np.pi, dtype=tf.float64))\n",
        "        phi = tf.Variable(tf.random.uniform(shape1, minval=0, maxval=np.pi, dtype=tf.float64))\n",
        "        alpha = tf.Variable(tf.random.uniform(shape2, minval=-3.0, maxval=3.0, dtype=tf.float64))\n",
        "        theta1 = tf.Variable(tf.random.uniform(shape3, minval=0, maxval=np.pi, dtype=tf.float64))\n",
        "        theta2 = tf.Variable(tf.random.uniform(shape3, minval=0, maxval=np.pi, dtype=tf.float64))\n",
        "        Xvec = pack_params_ansatz(beta, phi, alpha, theta1, theta2)\n",
        "    else:\n",
        "        Xvec = tf.Variable(Xvec, dtype=tf.float64)  # Ensure Xvec is a Variable\n",
        "\n",
        "    # Loss function\n",
        "    @tf.function\n",
        "    def loss_fun(Xvec):\n",
        "        psi = state_from_multimode_snap_tf(Xvec, ndepth, nfocks, vac, dtype=tf.complex128)\n",
        "        return energy_val_tf(psi, Zop, nfocks, T_list, coeffs)\n",
        "\n",
        "    # Gradient function\n",
        "    @tf.function\n",
        "    def value_and_gradients_function(Xvec):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(Xvec)\n",
        "            loss = loss_fun(Xvec)\n",
        "        gradients = tape.gradient(loss, Xvec)\n",
        "        return loss, gradients\n",
        "\n",
        "    # Run BFGS optimization\n",
        "    result = tfp.optimizer.bfgs_minimize(\n",
        "        value_and_gradients_function,\n",
        "        initial_position=Xvec,\n",
        "        tolerance=threshold,\n",
        "        max_iterations=niter\n",
        "    )\n",
        "\n",
        "    # Final result\n",
        "    final_loss = loss_fun(result.position)\n",
        "\n",
        "    return final_loss, result.position, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_aB9d0od0iI"
      },
      "source": [
        "## Explore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-UNkz5JWSDw"
      },
      "source": [
        "Load the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7WWPi6nd2Eo"
      },
      "outputs": [],
      "source": [
        "fname = 'snap-four-qubit-dict_nd16.npy'\n",
        "\n",
        "op_dict = np.load(fname, allow_pickle=True).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iNBNEuBWU9h"
      },
      "source": [
        "Get `QubitOperator` for the Hamiltonian of linear equidistant H$_4$ molcule in minimal basis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngwQiMqWdlZh"
      },
      "outputs": [],
      "source": [
        "hhdis = 0.5 # in Angstrom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRjs5Md_m7FY",
        "outputId": "507c579d-27ec-4667-d6d4-8ac95d12562b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.628609703029901, -1.6531169519401132)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "fci_linear_sym_h4(hhdis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gIqKU3ym0JP"
      },
      "outputs": [],
      "source": [
        "ham_op = ham_linear_sym_h4(hhdis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIg1F_XtXeGq"
      },
      "source": [
        "Get SNAP-displacement unitaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYPlbCp0XboB"
      },
      "outputs": [],
      "source": [
        "U1_list, U2_list, coeffs = snap_eight_qubit_ham(ham_op, op_dict)\n",
        "\n",
        "cvec = tf.constant( np.real(coeffs), dtype=tf.float64 )\n",
        "T_list = hadamard_ops_tf(U1_list, U2_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tojs5QHtQcJI"
      },
      "source": [
        "VQE."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ndepth = 20\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "en, Xvec, result = snap_vqe_tfp(T_list, cvec, ndepth, niter=2000,\n",
        "                                threshold=1e-12)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"en: \", en.numpy())\n",
        "print(\"iters: \", result.num_iterations.numpy())\n",
        "print(\"time in mins: \", ( end_time - start_time ) / 60 )"
      ],
      "metadata": {
        "id": "fwbX2a7wdhoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "J0tBc-IKGzVS",
        "gemSMnUZTp5M",
        "MeO4HjsUCo5b",
        "Olo-M0zHmXEE",
        "a6XBKiSqbvIO"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}